---
title: "statistical_analysis"
author: "Dominik Dianovics"
format: html
---

# Researcher burnout and questionable research practice pilot data analysis

## Statistical analysis

### Load libraries

```{r echo = FALSE ouput = FALSE}
if(!require("tidyverse")) install.packages("tidyverse")
if(!require("here")) install.packages("here")
if(!require("lavaan")) install.packages("lavaan")
if(!require("MVN")) install.packages("MVN")
if(!require("semPlot")) install.packages("semPlot")
if(!require("influence.SEM")) install.packages("influence.SEM")
if(!require("mice")) install.packages("mice")
if(!require("devtools")) install.packages("devtools")
if(!require("semPower")) install.packages("semPower")
if(!require("car")) install.packages("car")
if(!require("MASS")) install.packages("MASS")
library(tidyverse)
library(here)
library(ggplot2)
library(lavaan)
library(MVN)
library(semPlot)
library(influence.SEM)
library(mice)
library(devtools)
library(semPower)
library(car)
library(MASS) 
data_path <- here("data")

```

### Load data

```{r echo = FALSE ouput = FALSE}
data = read_csv(here::here("data/processed/aggregated_data.csv"))
```

# Latent variables as imagined by the Job Demands-Resources Model of Burnout

# Job demands and resources

```{r}
# Additional information:
# Scores are aggregate means of the respective scales.
# For a larger dataset, parceling or item-level analysis could be rlcsidered.
# Missing data imputation was not performed for SEM
# There is multivariate non-normality, so robust ML estimation is used.
# Data is linear, and no multicollinearity issues were detected.
# Outliers were detected using Cook's distance, and a model without outliers was also evaluated.
# The proposed model is familiar to you, however, in the final model, I have taken the pay, tool, and general satisfaction items out of the job resources latent variable due to their low loadings and high residuals.
```

## Job demands as latent variable measured by item-level indicators

```{r}
#Job demands are: workload, pubplication pressure_stress, publication_pressure_attitude, role stressors such as rlaiguity and rlcflict, work-life balance

job_demands_item = data |>
  dplyr::select(anonym_id, starts_with(c("wld_", "ppa_", "pps_", "rla_", "rlc_", "wlb_")))

job_demands_latent_item = cfa(
  '
  # First-order factors
  wld =~ wld_1 + wld_2 + wld_3 + wld_4
  ppa =~ ppa_7 + ppa_8 + ppa_9 + ppa_10 + ppa_11 + ppa_12
  pps =~ pps_1 + pps_2 + pps_3 + pps_4 + pps_5 + pps_6
  rla =~ rla_1 + rla_2 + rla_3 + rla_4 + rla_5 + rla_6
  rlc =~ rlc_1 + rlc_2 + rlc_3 + rlc_4 + rlc_5 + rlc_6
  wlb =~ wlb_1 + wlb_2 + wlb_3 + wlb_4
  
  # Structural model
  job_demands =~ wld + ppa + pps + rla + rlc + wlb
  
  # Residual correlations based on theory and expected overlap
    rla ~~ rlc
    rlc_1 ~~ rlc_6
  ',
  data = job_demands_item,
  estimator = "MLR",
  std.lv = TRUE
)
summary(job_demands_latent_item, fit.measures = TRUE, standardized = TRUE, modindices = TRUE)


summary_text <- capture.output(summary(job_demands_latent_item, fit.measures = TRUE, standardized = TRUE, modindices = TRUE))
writeLines(summary_text, here::here("analysis/tables/job_demands_summary.txt"))
pdf(here::here("analysis/figures/demands_cfa_plot.pdf"), width = 10, height = 8)
semPaths(job_demands_latent_item, what = "std", style = "lisrel", layout = "tree", residuals = TRUE, rotation = 4, sizeMan = 12, sizeMan2 = 6, nCharNodes = 6)
dev.off()
```

## Job demands as latent variable measured by construct-level indicators

```{r}
#Job demands are: workload, pubplication pressure_stress, publication_pressure_attitude, role stressors such as rlaiguity and rlcflict, work-life balance

job_demands = data |>
  dplyr::select(anonym_id, wld, ppa, pps, rla, rlc, wlb)

job_demands_latent = cfa(
  '
  # Measurement model
  job_demands =~ wld + ppa + pps + rla + rlc + wlb
  
  # Residual correlations based on theory and expected overlap
    rla ~~ rlc
  ',
  data = job_demands,
  estimator = "MLR",
  std.lv = TRUE
)
summary(job_demands_latent, fit.measures = TRUE, standardized = TRUE, modindices = TRUE)


summary_text <- capture.output(summary(job_demands_latent, fit.measures = TRUE, standardized = TRUE, modindices = TRUE))
writeLines(summary_text, here::here("analysis/tables/job_demands_summary.txt"))
pdf(here::here("analysis/figures/demands_cfa_plot.pdf"), width = 10, height = 8)
semPaths(job_demands_latent, what = "std", style = "lisrel", layout = "tree", residuals = TRUE, rotation = 4, sizeMan = 12, sizeMan2 = 6, nCharNodes = 6)
dev.off()
```

## Job resources as latent variable measured by item-level indicators

```{r}
job_resources_item = data |>
  dplyr::select(anonym_id, starts_with(c("opp_", "mng_", "inf_", "soc_", "ppr_", "sec_")))

job_resources_latent_item = cfa(
  '
  opp =~ opp_1 + opp_2 + opp_3
  opp ~~ 1*opp
  mng =~ mng_1 + mng_2
  mng ~~ 1*mng
  inf =~ inf_1 + inf_2 + inf_3 + inf_4 + inf_5 + inf_6
  inf ~~ 1*inf
  soc_sup =~ soc_1 + soc_2 + soc_3 
  soc_sup ~~ 1*soc_sup
  soc_col =~ soc_4 + soc_5 + soc_6
  soc_col ~~ 1*soc_col
  ppr =~ ppr_13 + ppr_14 + ppr_15 + ppr_16 + ppr_17 + ppr_18
  ppr ~~ 1*ppr
  sec =~ sec_1 + sec_2 + sec_3 + sec_4
  sec ~~ 1*sec
  
  job_resources =~ opp + mng + inf + soc_sup + soc_col + ppr + sec
  job_resources ~~ 1*job_resources
  ',
  data = job_resources_item,
  estimator = "MLR",
  std.lv = TRUE
)
summary(job_resources_latent_item, fit.measures = TRUE, standardized = TRUE, modindices = TRUE)
modindices(job_resources_latent_item, sort = TRUE)

summary_text <- capture.output(summary(job_resources_latent_item, fit.measures = TRUE, standardized = TRUE, modindices = TRUE))
writeLines(summary_text, here::here("analysis/tables/job_resources_summary.txt"))

pdf(here::here("analysis/figures/resources_cfa_plot.pdf"), width = 10, height = 8)
semPaths(job_resources_latent_item, what = "stand", layout = "tree", rotation = 4, sizeMan = 12, sizeMan2 = 6, nCharNodes = 6)
dev.off()
```

## Job resources as latent variable measured by construct-level indicators

```{r}
#Job resources are: opportunities, meaning, influence, social support, job insecurity

job_resources = data |>
  dplyr::select(anonym_id, opp, mng, inf, soc, ppr, sec)

job_resources_latent = cfa(
  '
  job_resources =~ opp + mng + inf + soc + ppr + sec
  ',
  data = job_resources,
  estimator = "MLR",
  std.lv = TRUE
)
summary(job_resources_latent, fit.measures = TRUE, standardized = TRUE, modindices = TRUE)
modindices(job_resources_latent, sort = TRUE)

summary_text <- capture.output(summary(job_resources_latent, fit.measures = TRUE, standardized = TRUE, modindices = TRUE))
writeLines(summary_text, here::here("analysis/tables/job_resources_summary.txt"))

pdf(here::here("analysis/figures/resources_cfa_plot.pdf"), width = 10, height = 8)
semPaths(job_resources_latent, what = "stand", layout = "tree", rotation = 4, sizeMan = 12, sizeMan2 = 6, nCharNodes = 6)
dev.off()
```

## Job demands and resources plus burnout: Structural equation modeling

```{r}
jdr_b_model = '
  # Measurement model
  job_demands =~ wld + ppa + pps + rla + rlc + wlb
  job_resources =~ opp + mng + inf + soc + pay + tol + ppr + gnl + sec
  
  # Residual correlations
  rla ~~ rlc
  pay ~~ tol
  
  # Structural model
  brt ~ job_demands + job_resources
'
```

### JDR-Burnout model fitting

```{r}
jdr_b_fit = sem(jdr_b_model, data = data, std.lv = TRUE, estimator = "MLR", se = "robust.sem")

summary(jdr_b_fit, fit.measures = TRUE, standardized = TRUE, modindices = TRUE, rsquare = TRUE)
modindices(jdr_b_fit, sort = TRUE)
# compRelSEM(jdr_b_fit, higher = c("job_demands", "job_resources"))  # if model uses latent variables


summary_text <- capture.output(summary(jdr_b_fit, fit.measures = TRUE, standardized = TRUE, modindices = TRUE))
writeLines(summary_text, here::here("analysis/tables/jdr_burnout_fit_summary.txt"))
```

### Visualizing model

```{r}
pdf(here::here("analysis/figures/sem_plot.pdf"), width = 10, height = 8)
semPaths(jdr_b_fit, 
         what = "stand", 
         layout = "tree2", 
         rotation = 2,
         style = "mx",
         posCol = "black",
         negCol = "black",
         nCharNodes = 0,
         residuals = TRUE,
         weighted = TRUE,
         optimizeLatRes = TRUE,
         fade = FALSE,
         edge.color = "black",
         mar = c(3, 5, 3, 5)
         )
dev.off()
```

### Evaluating model

```{r}
inspect(jdr_b_fit, "std")
```

# Checking convergent validity

```{r}
jdr_measurement_model <- '
  # First-order factors
  wld =~ copsoq_workload_1 + copsoq_workload_2 + copsoq_workload_3 + copsoq_workload_4
  ppa =~ ppqr_attitude_7 + ppqr_attitude_8 + ppqr_attitude_9 + ppqr_attitude_10 + ppqr_attitude_11 + ppqr_attitude_12
  pps =~ ppqr_stress_1 + ppqr_stress_2 + ppqr_stress_3 + ppqr_stress_4 + ppqr_stress_5 + ppqr_stress_6
  rla =~ role_rlaiguity_01 + role_rlaiguity_02 + role_rlaiguity_03 + role_rlaiguity_04 + role_rlaiguity_05 + role_rlaiguity_06
  rlc =~ role_rlcflict_07 + role_rlcflict_08 + role_rlcflict_09 + role_rlcflict_10 + role_rlcflict_11 + role_rlcflict_12
  wlb =~ wlbm_1 + wlbm_2 + wlbm_3 + wlbm_4

  opp =~ copsoq_oppor_1 + copsoq_oppor_2 + copsoq_oppor_3
  mng =~ copsoq_meaning_1 + copsoq_meaning_2
  inf =~ copsoq_infl_1 + copsoq_infl_2 + copsoq_infl_3 + copsoq_infl_4
  soc =~ copsoq_soc_sup_1 + copsoq_soc_sup_2 + copsoq_soc_sup_3 + copsoq_soc_sup_4
  sec =~ jis_1 + jis_2 + jis_3 + jis_4
  ppr =~ ppqr_resources_13 + ppqr_resources_14 + ppqr_resources_15 + ppqr_resources_16 + ppqr_resources_17 + ppqr_resources_18

  # serlcd-order factors
  job_demands =~ wld + ppa + pps + rla + rlc + wlb
  job_resources =~ opp + mng + inf + soc + sec + ppr
'

jdr_fit <- cfa(
  jdr_measurement_model,
  data = processed_filtered,
  estimator = "MLR",
  std.lv = TRUE
)


stdsol <- standardizedSolution(jdr_fit)

# Extract serlcd-order loadings for job demands
load_dem <- subset(stdsol, lhs == "job_demands" & op == "=~")[, "est.std"]

# Extract residual variances of first-order factors
resid_dem <- subset(stdsol, lhs == "job_demands" & op == "~~" & rhs != lhs)[, "est.std"]

r2_vals <- inspect(jdr_fit, "r2")

resid_dem <- 1 - r2_vals[c("wld", "ppa", "pps", "rla", "rlc", "wlb")]

AVE_dem <- sum(load_dem^2) / (sum(load_dem^2) + sum(resid_dem))
AVE_dem

load_res <- subset(stdsol, lhs == "job_resources" & op == "=~")[, "est.std"]
resid_res <- 1 - r2_vals[c("opp", "mng", "inf", "soc", "sec", "ppr")]

AVE_res <- sum(load_res^2) / (sum(load_res^2) + sum(resid_res))
AVE_res

htmt(jdr_fit)

```

# Assumptions for the models

### Multicollinearity

```{r}
correlation_matrix <- data_normality  |> 
  cor(use = "pairwise.complete.obs") |>
  round(2)

correlation_matrix_filtered <- correlation_matrix
correlation_matrix_filtered[abs(correlation_matrix_filtered) < 0.50] <- ""

correlation_matrix_filtered <- as.data.frame(correlation_matrix_filtered)
correlation_matrix_filtered


lm_vif <- lm(burnout ~ wld + ppa + pps + rla + rlc + wlb + opp + mng + inf + soc + pay + tol + ppr + gnl + sec, data = linearity_data)
vif(lm_vif)

lm_vif_structural <- lm(burnout_total ~ job_demands_total + job_resources_total, data = linearity_data)
vif(lm_vif)

# No multicollinearity issues detected (all correlations < 0.70)
```

### Outlier detection

```{r}
cooks_d <- genCookDist(jdr_b_fit, data = data)

outlier_df <- data %>%
  mutate(
    id = seq_len(nrow(.)),
    cooks_d = cooks_d,
    is_outlier_cooks = cooks_d > 1   # or 0.5 depending on preference
  )

plot(outlier_df$cooks_d, type = "h", main = "Cook's Distance", ylab = "Cook's Distance")

data_no_outliers <- outlier_df %>% 
  filter(!is_outlier_cooks) %>% 
  dplyr::select(-c(cooks_d, is_outlier_cooks))  # remove diagnostics columns


# Refit the model without outliers

fit_no_outlier <- sem(model = jdr_b_model,
                data = data_no_outliers,
                std.lv = TRUE,
                estimator = "MLR",
                missing = "listwise",
                verbose = TRUE)

summary(fit_no_outlier, fit.measures = TRUE, standardized = TRUE, modindices = TRUE, rsquare = TRUE)
modindices(fit_no_outlier, sort = TRUE)
```

# Final model

```{r}
write.csv(data_no_outliers, here::here("data/processed/data_no_outliers.csv"), row.names = FALSE)

# ppa also removed
jdr_final_model = '
  # Measurement model
  job_demands =~ wld + pps + rla + rlc + wlb
  job_resources =~ opp + mng + inf + soc + ppr + sec
  
  # Residual correlations
  rla ~~ rlc
  
  # Structural model
  brt ~ job_demands + job_resources
  '

jdr_final_fit = sem(jdr_final_model, data = data_no_outliers, std.lv = TRUE, estimator = "MLR")

summary(jdr_final_fit, fit.measures = TRUE, standardized = TRUE, modindices = TRUE, rsquare = TRUE)
modindices(jdr_final_fit, sort = TRUE)


```

# Calculating power of final model

```{r}
Sigma <- lavInspect(jdr_final_fit, "cov.ov")
mu <- lavInspect(jdr_final_fit, "mean.ov")
vars <- names(mu)

posthoc_power <- function(nobs = nrow(data_no_outliers), n_sim = 1000, alpha = 0.05) {
  replicate(n_sim, {
    sim_data <- as.data.frame(MASS::mvrnorm(n = nobs, mu = mu, Sigma = Sigma))
    colnames(sim_data) <- vars
    
    sim_fit <- sem(jdr_final_model, data = sim_data, std.lv = TRUE, estimator = "MLR", missing = "fiml")
    
    est <- parameterEstimates(sim_fit)
    paths <- est %>%
      filter(op == "~", lhs == "brt", rhs %in% c("job_demands", "job_resources")) %>%
      pull(pvalue)
    
    paths < alpha  
  }, simplify = "matrix")
}

n_pilot <- nrow(data_no_outliers)
sim_results <- posthoc_power(nobs = n_pilot, n_sim = 1000)

power_job_demands <- mean(sim_results[1, ])
power_job_resources <- mean(sim_results[2, ])

cat("Post-hoc power (job_demands → burnout):", round(power_job_demands, 3), "\n")
cat("Post-hoc power (job_resources → burnout):", round(power_job_resources, 3), "\n")

# Estimating sample size for 0.80 power in final model

Sigma <- lavInspect(jdr_final_fit, "cov.ov")   
mu <- lavInspect(jdr_final_fit, "mean.ov")   
vars <- names(mu)

simulate_power <- function(nobs, alpha = 0.05, n_sim = 500) {
  replicate(n_sim, {
    sim_data <- as.data.frame(MASS::mvrnorm(n = nobs, mu = mu, Sigma = Sigma))
    colnames(sim_data) <- vars
    
    sim_fit <- sem(jdr_final_model, data = sim_data, std.lv = TRUE, estimator = "MLR", missing = "fiml")
    
    est <- parameterEstimates(sim_fit)
    paths <- est %>%
      filter(op == "~", lhs == "burnout", rhs %in% c("job_demands", "job_resources")) %>%
      pull(pvalue)
    
    paths < alpha 
  }, simplify = "matrix")
}

sample_sizes <- seq(200, 1000, by = 200)

power_results <- tibble(N = integer(), power_job_demands = numeric(), power_job_resources = numeric())

for (n in sample_sizes) {
  cat("Simulating for N =", n, "\n")
  
  sim <- simulate_power(nobs = n, n_sim = 500)
  
  power_results <- power_results %>%
    add_row(
      N = n,
      power_job_demands = mean(sim[1, ]),
      power_job_resources = mean(sim[2, ])
    )
}

power_results %>%
  filter(power_job_demands >= 0.8 | power_job_resources >= 0.8) %>%
  arrange(N)

```


# Estimating power for the main SEM model

```{r}
semPower.getDf(jdr_b_model)

# Power to detect misspecified model

power_model_fit <- semPower(
  type = "a-priori",
  effect = 0.05,
  effect.measure = "RMSEA",
  alpha = 0.05,
  df = 100,
  power = 0.80
)

summary(power_model_fit)

# Power to detect target effect

inspect(jdr_b_fit, "std.all")


# pwrSEM was used with the following parameters:
## MODEL
### X =~ x1 + x2 + x3 + x4 + x5 + x6
### Y =~ y1 + y2 + y3 + y4 + y5 + y6 
### Z ~ Y + X

## PARAMETERS
### Factor loadings are inputed from pilot
### Regressions are inputed from pilot
### Variances are inputed from pilot
## Covariance is inputed from pilot

## Result of analysis based on 1100 simulations
### Effects of interest: burnout ~ job demands, burnout ~ job resources
### Minimum sample size for 0.80 power is 450
### Lowest power estimation was for burnout ~ job resources (0.80)

```
